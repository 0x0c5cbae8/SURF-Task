{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hbyh1F9Hxqdv"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset, concatenate_datasets\n",
        "import random\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "random.seed(1315)\n",
        "\n",
        "dataset_id = \"allenai/pixmo-count\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "\n",
        "ds_train = load_dataset(dataset_id, split=\"train\")\n",
        "ds_test = load_dataset(dataset_id, split=\"test\") # only contains counts from 2 to 10\n",
        "\n",
        "group_size = 56\n",
        "\n",
        "ds_train = ds_train.filter(lambda x: x[\"count\"]==1)\n",
        "ds = ds_train.select(random.sample(range(len(ds_train)), group_size+10))\n",
        "ds = concatenate_datasets([ds, ds_test.filter(lambda x: x[\"count\"]<=5)])\n",
        "\n",
        "# ds_i = [ds_train.filter(lambda x: x[\"count\"]==i) for i in range(5)]\n",
        "# ds_i = [d.select(random.sample(range(len(d)), group_size+10)) for d in ds_i]\n",
        "# ds = concatenate_datasets(ds_i)"
      ],
      "metadata": {
        "id": "HWxj_8mSx_ox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(ds))"
      ],
      "metadata": {
        "id": "9NY6ZuIqyNpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# construct input/output\n",
        "\n",
        "counts = [0,0,0,0,0]\n",
        "\n",
        "def generate_iopair(data):\n",
        "    if counts[data[\"count\"]-1] >= group_size:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        response = requests.get(data[\"image_url\"], timeout=3)\n",
        "\n",
        "        response.raise_for_status()\n",
        "\n",
        "        image_input = Image.open(BytesIO(response.content))\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "    counts[data[\"count\"]-1] += 1\n",
        "    print(counts)\n",
        "\n",
        "    return {\n",
        "        \"text\": data[\"label\"],\n",
        "        \"image\": image_input,\n",
        "        \"label\": data[\"count\"]\n",
        "    }\n",
        "\n",
        "dataset = []\n",
        "for item in ds:\n",
        "    res = generate_iopair(item)\n",
        "    if res is not None:\n",
        "        dataset.append(res)"
      ],
      "metadata": {
        "id": "h1eJSZ5typ90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grouped_dataset = {label: [] for label in range(1, 6)}\n",
        "for item in dataset:\n",
        "    grouped_dataset[item[\"label\"]].append(item)\n",
        "\n",
        "interleaved_dataset = []\n",
        "max_len = max(len(grouped_dataset[label]) for label in grouped_dataset)\n",
        "\n",
        "for i in range(max_len):\n",
        "    for label in range(1, 6):\n",
        "        if i < len(grouped_dataset[label]):\n",
        "            interleaved_dataset.append(grouped_dataset[label][i])\n",
        "\n",
        "dataset = interleaved_dataset"
      ],
      "metadata": {
        "id": "tnyPx4og0nJU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e091d72"
      },
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "output_dir = \"dataset_images\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "metadata = []\n",
        "\n",
        "for i, item in enumerate(dataset):\n",
        "    image_filename = f\"{i}.jpg\"\n",
        "    image_path = os.path.join(output_dir, image_filename)\n",
        "\n",
        "    item[\"image\"].convert(\"RGB\").save(image_path)\n",
        "\n",
        "    entry = {\n",
        "        \"label\": item[\"text\"],\n",
        "        \"count\": item[\"label\"],\n",
        "        \"index\": i\n",
        "    }\n",
        "    metadata.append(entry)\n",
        "\n",
        "with open(\"dataset.json\", \"w\") as f:\n",
        "    json.dump(metadata, f, indent=4)\n",
        "\n",
        "print(f\"Saved {len(dataset)} images to '{output_dir}/' and metadata to 'dataset.json'.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "275ef28a"
      },
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Zip the dataset_images directory\n",
        "shutil.make_archive('dataset_images', 'zip', 'dataset_images')\n",
        "\n",
        "# Download the zip file\n",
        "files.download('dataset_images.zip')\n",
        "files.download('dataset.json')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}